{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络CNN\n",
    "\n",
    "`convolution`代表卷积，CNN就是卷积神经网络的缩写。\n",
    "\n",
    "使用特殊的卷积层和池化层来构建网络，进而得到输入数据的某些特征。\n",
    "\n",
    "### 卷积`convolution`\n",
    "\n",
    "卷积是一种数学运算，定义为$\\displaystyle (f*g)(n)=\\int _{-\\infty }^{\\infty }f(\\tau )g(n-\\tau )d\\tau$，离散情况下定义为$\\displaystyle (f*g)(n)=\\sum _{\\tau =-\\infty }^{\\infty }{f(\\tau )g(n-\\tau )}$，也就是求所有的和为$n$的两个数的组合，把这些数组中的两个元素分别用$f$和$g$两个函数作用，求其乘积之和。\n",
    "\n",
    "具体可以参考https://www.zhihu.com/question/22298352/answer/228543288\n",
    "\n",
    "其中有一种“卷”的操作，也就是把两个函数卷到了一起。\n",
    "\n",
    "我们已有的输入，可以作为其中的一个函数，另一个函数就是我们所说的`卷积核`。而函数里面的$n$，是新的函数中的变量。也就是说，从两个函数创建出一个新的函数，这个新的函数就是卷积。\n",
    "\n",
    "![convolution](Tensorflow07-CNN.assets/1550923413901.png)\n",
    "\n",
    "卷积对应的运算就是这个样子，中间的不动的是卷积核。\n",
    "\n",
    "其实本质上就是把一个范围内的特征提取出来。\n",
    "\n",
    "### 池化`pooling`\n",
    "\n",
    "池化就是为了削减数据量，提取其中有意义的信息。\n",
    "\n",
    "一定范围内的数据进行处理，比如把这个范围内的最大值取出，平均值取出。\n",
    "\n",
    "![maxpool](Tensorflow07-CNN.assets/20170810231546983)\n",
    "\n",
    "可以起到如下作用：\n",
    "\n",
    "- 大大降低特征的维数，避免过拟合\n",
    "- 可去除一些冗余信息，得到一个低分辨率的特征图\n",
    "- 使得模型更关注是否存在某些特征而不是特征的具体位置，可以容忍一些特征微小的位移\n",
    "\n",
    "参考：\n",
    "\n",
    "- https://blog.csdn.net/fontthrone/article/details/76652762\n",
    "- https://blog.csdn.net/mzpmzk/article/details/78636184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现\n",
    "\n",
    "### 卷积\n",
    "\n",
    "卷积直接可以使用`tf.layers.conv2d`或者`tf.nn.conv2d`进行操作。\n",
    "\n",
    "前者的参数：\n",
    "\n",
    "``` python\n",
    "tf.layers.conv2d(\n",
    "    inputs,\n",
    "    filters,     # 卷积核个数\n",
    "    kernel_size,  # 卷积核大小，如[5，5]。如果长宽相等，也可以直接设置为一个数，如kernel_size=5\n",
    "    strides=(1, 1), # 卷积过程中的滑动步长，默认为[1,1]. 也可以直接设置为一个数，如strides=2\n",
    "    padding='valid',  # 边缘填充，'same' 和'valid‘选其一，\"valid\" 表示不够卷积核大小的块就丢弃，\"same\"表示不够卷积核大小的块就补0。\n",
    "    data_format='channels_last',  # 输入数据格式，默认为channels_last ，即 (batch, height, width, channels),也可以设置为channels_first 对应 (batch, channels, height, width)\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer=None,\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    trainable=True,  # 表明该层的参数是否参与训练\n",
    "    name=None,\n",
    "    reuse=None\n",
    ")\n",
    "\n",
    "# 例子：\n",
    "conv1 = tf.layers.conv2d(batch_images, \n",
    "                         filters=64,\n",
    "                         kernel_size=7,\n",
    "                         strides=2,\n",
    "                         activation=tf.nn.relu,\n",
    "                         kernel_initializer=tf.TruncatedNormal(stddev=0.01)\n",
    "                         bias_initializer=tf.Constant(0.1),\n",
    "                         kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003),\n",
    "                         bias_regularizer=tf.contrib.layers.l2_regularizer(0.003),\n",
    "                         name='conv1')\n",
    "```\n",
    "\n",
    "后者的参数：\n",
    "\n",
    "``` python\n",
    "tf.nn.conv2d(\n",
    "    input,  # 一个4维Tensor（N,H,W,C)\n",
    "    filter,\n",
    "    strides,\n",
    "    padding,\n",
    "    use_cudnn_on_gpu=None,\n",
    "    data_format=None,  # 可选项，指定输入数据的格式: \"NHWC\"或 \"NCHW\"， 默认为\"NHWC\"。NHWC格式指[batch, in_height, in_width, in_channels]；NCHW格式指[batch, in_channels, in_height, in_width]\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "参考：\n",
    "\n",
    "- http://www.cnblogs.com/denny402/p/6932186.html\n",
    "- https://blog.csdn.net/gqixf/article/details/80519912\n",
    "\n",
    "### 池化\n",
    "\n",
    "最大池化：`tf.layers.max_pooling2d`或者`tf.nn.max_pool`，均值池化：`tf.layers.average_pooling2d`或者`tf.nn.avg_pool`。\n",
    "\n",
    "参数：\n",
    "``` python\n",
    "tf.layers.max_pooling2d(\n",
    "  inputs,\n",
    "  pool_size, # 池化的核大小\n",
    "  strides,  # 池化的滑动步长\n",
    "  padding='valid',\n",
    "  data_format='channels_last',\n",
    "  name=None\n",
    ")\n",
    "\n",
    "tf.nn.max_pool(\n",
    "    value, \n",
    "    ksize,   # 池化窗口的大小，形状为[1, height, weight, 1]，因为我们不想在batch 和 channels 上做池化，所以这两个维度设为了1\n",
    "    strides,\n",
    "    padding, \n",
    "    data_format='NHWC', \n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "参考：\n",
    "\n",
    "- https://www.jb51.net/article/139009.htm\n",
    "- https://blog.csdn.net/mzpmzk/article/details/78636184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码示例\n",
    "\n",
    "依旧使用MNIST进行示例。\n",
    "\n",
    "*注：若出现：`UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`，就要考虑 tensorflow版本不对的问题。*\n",
    "\n",
    "参考：\n",
    "\n",
    "- https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf18_CNN3/full_code.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0.1205\n",
      "0.7962\n",
      "0.8731\n",
      "0.908\n",
      "0.924\n",
      "0.9327\n",
      "0.9381\n",
      "0.943\n",
      "0.9451\n",
      "0.9496\n",
      "0.954\n",
      "0.9516\n",
      "0.9569\n",
      "0.9593\n",
      "0.9621\n",
      "0.9625\n",
      "0.9662\n",
      "0.9666\n",
      "0.9664\n",
      "0.9676\n",
      "0.9694\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # 这里修改了stddev\n",
    "    Weights = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.1))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "def add_conv2d_layer(inputs, input_height, out_size, kernal_size=5, activation_function=None):\n",
    "    Weights = tf.Variable(tf.truncated_normal([kernal_size, kernal_size, input_height, out_size], stddev=0.1))\n",
    "    biases = tf.Variable(tf.zeros([out_size]) + 0.1)\n",
    "    conved = tf.nn.conv2d(inputs, Weights, strides=[1, 1, 1, 1], padding='SAME') + biases\n",
    "    if activation_function is None:\n",
    "        outputs = conved\n",
    "    else:\n",
    "        outputs = activation_function(conved)\n",
    "    return outputs\n",
    "\n",
    "def add_max_pool_layer(inputs, kernal_size=2):\n",
    "    return tf.nn.max_pool(inputs, ksize=[1, kernal_size, kernal_size, 1], strides=[1, kernal_size, kernal_size, 1], padding='SAME')\n",
    "\n",
    "def compute_accuracy(v_xs_all, v_ys_all):\n",
    "    global prediction\n",
    "    step = 1000\n",
    "    index = 0\n",
    "    length = len(v_xs_all) // step * step\n",
    "    result = 0\n",
    "    while index < length - 1:\n",
    "        v_xs = v_xs_all[index:index+step]\n",
    "        v_ys = v_ys_all[index:index+step]\n",
    "        y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "        correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "        result += sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "        index += step\n",
    "    return float(result) / length\n",
    "\n",
    "xs = tf.placeholder(tf.float32, [None, 28 * 28])\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "\n",
    "# 经过卷积，形状中长宽不变，结果为?*28*28*32（注意卷积过程中会进行padding操作）\n",
    "conv1 = add_conv2d_layer(x_image, 1, 32, activation_function=tf.nn.relu)\n",
    "# 池化后，形状变为?*14*14*32\n",
    "pool1 = add_max_pool_layer(conv1)\n",
    "conv2 = add_conv2d_layer(pool1, 32, 64, activation_function=tf.nn.relu)\n",
    "# 现在形状为?*7*7*64\n",
    "pool2 = add_max_pool_layer(conv2)\n",
    "\n",
    "# 添加全连接层，之前先压扁，形状是?*(7*7*64)\n",
    "flatten = tf.reshape(pool2, [-1, 7*7*64])\n",
    "inner = add_layer(flatten, 7*7*64, 1024, activation_function=tf.nn.relu)\n",
    "dropped = tf.nn.dropout(inner, keep_prob)\n",
    "\n",
    "prediction = add_layer(dropped, 1024, 10, activation_function=tf.nn.softmax)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))\n",
    "# 使用Adam优化器加速\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(1001):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "        if i % 50 == 0:\n",
    "            print(compute_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
