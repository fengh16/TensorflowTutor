{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "\n",
    "B站视频：https://www.bilibili.com/video/av43268598/\n",
    "\n",
    "之前一直在使用`GradientDescentOptimizer`，但是梯度下降算法只是优化器的一种，可以使用别的一些更快的算法来进行这一步骤。\n",
    "\n",
    "- SGD：\n",
    "  - Stochastic Gradient Descent，随机梯度下降，引入随机因素。\n",
    "  - 计算梯度的时候，不计算准确的梯度，只是用一部分来算出一个不太准确的梯度。\n",
    "  - 因此会节省计算资源，同时可以避免陷入鞍点的情况。\n",
    "    - ![saddle point](Tensorflow04-Optimizer.assets/1549891679229.png)\n",
    "    - 鞍点处梯度为0，无法更新。\n",
    "  - 也可以避免陷入局部最优无法出来\n",
    "    - 因为如果进入局部最优，就会有一个随机的扰动，可能让他出来。   \n",
    "- Momentum：\n",
    "  - 在梯度下降的基础上，再加上之前一次变量变化的量 的若干倍\n",
    "  - $w(t+1)=w(t)-\\mu\\frac{\\partial E}{\\partial w} + \\beta(w(t)-w(t-1)), 0\\le \\beta < 1$\n",
    "- AdaGrad：\n",
    "  - 考虑两个不同方向的变化，将震荡比较大的方向的变化减小\n",
    "  - 因此相当于降低学习率，除以所有历史变化的平方和开根号\n",
    "  - $w(t+1)=w(t)-\\mu\\frac{\\partial E}{\\partial w} \\frac 1{\\sqrt{v+\\epsilon}}, v=\\sum\\limits_{i=1}^{t-1}(w(i+1)-w(i))^2$\n",
    "- RMSProp：\n",
    "  - 因为AdaGrad里面的平方和开根号会越来越大，所以学习率越来越小，中后期导致训练提前结束\n",
    "  - 所以采用一种平滑的方法计算学习率的减少量\n",
    "  - $w(t+1)=w(t)-\\mu\\frac{\\partial E}{\\partial w} \\frac 1{\\sqrt{v(t)+\\epsilon}}, v(t)=(1-\\beta)v(t-1) + \\beta (w(i+1)-w(i))^2$\n",
    "- Adam：\n",
    "  - 综合Momentum和RMSProp：\n",
    "    - $w(t+1)=w(t)-\\mu\\left(\\frac{\\partial E}{\\partial w} + \\beta_0(w(t)-w(t-1))\\right) \\frac 1{\\sqrt{v(t)+\\epsilon}},$$ v(t)=(1-\\beta)v(t-1) + \\beta (w(i)-w(i-1))^2$\n",
    "\n",
    "### tensorflow中使用\n",
    "\n",
    "可以使用：\n",
    "\n",
    "- GradientDescentOptimizer\n",
    "- AdadeltaOptimizer\n",
    "- AdagradOptimizer\n",
    "- MomentumOptimizer\n",
    "- AdamOptimizer\n",
    "- FtrlOptimizer\n",
    "- RMSPropOptimizer\n",
    "\n",
    "\n",
    "参考：\n",
    "- https://zhuanlan.zhihu.com/p/27609238\n",
    "- https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/3-4-A-speed-up-learning/\n",
    "- https://blog.csdn.net/garfielder007/article/details/51058752\n",
    "- https://www.cnblogs.com/jiaxblog/p/9695042.html\n",
    "- https://zhuanlan.zhihu.com/p/22252270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
